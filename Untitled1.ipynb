{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELECTION ANALYSIS AND PREDICTION - INDIA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PROBLEM STATEMENT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to identify the factors which play a substantial role in deciding the winning candiature in the Indian elections. Using Linear Regression, we calcuate a \"score\" and assign it to each candidate contesting the election. The score is a correlation of the candidate's chances of winning or losing. <br> <br>\n",
    "We further calcuate feature importance using Random Forest Algorithm to determine which features significantly dominate in curating this model's result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. BACKGROUND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "India holds the general elections for the lower house of the parliament after every five years. Elections are held over 543 seats (total number of elected candidates) across 29 states and 7 Union Territories. With over 900 million elligible voters and more than 7000 candidates in 2019, the general elections in India are the largest in the world. <br> <br>\n",
    "The data for the 2019 elections has not yet been published by the Election Commission of India. For this project, the available data from 2004, 2009 and 2014 elections is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 DATA COLLECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in the project has been scraped from https://www.myneta.info/ <br>\n",
    "The website has the database of all candidates contesting for the general elections in 2004, 2009 and 2014. <br>\n",
    "The respective links for the datasets of candidates for the three years are: <br>\n",
    "1. 2004 elections: http://myneta.info/ls2004/\n",
    "2. 2009 elections: http://myneta.info/ls2009/\n",
    "3. 2014 elections: http://myneta.info/ls2014/<br>\n",
    "\n",
    "According to the mentioned website :  \"The primary source for the data used for these reports is the sworn affidavits provided by the candidates themselves\" <br>\n",
    "\n",
    "The following is the code for the scraper:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries for the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Some packages will require installation by using the pip command. Packages can be installed by uncommenting code in the subsequent code block in case of an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment if package installation is required\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install pyquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from pyquery import PyQuery as pq\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 URL Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_2014 = \"http://myneta.info/ls2014/\"\n",
    "base_2009 = \"http://myneta.info/ls2009/\"\n",
    "base_2004 = \"http://myneta.info/loksabha2004/\"\n",
    "\n",
    "#url_list={'2004':ls_2004,'2009':ls_2009,'2014':ls_2014}\n",
    "base_urls = {'2004':base_2004,'2009':base_2009,'2014':base_2014}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Key functions to get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following function returns a dataframe of constituencies within a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constituents(year, thelink):\n",
    "    print(\"Fetching constituencies!\")\n",
    "    html = requests.get(thelink)\n",
    "    doc = pq(html.content)\n",
    "    trs = doc('table').eq(2).find('tr')\n",
    "    datalist=[]\n",
    "    for tr in trs:\n",
    "        new_state = pq(tr)('th').text()\n",
    "        if new_state != \"\":\n",
    "            curr_state = new_state \n",
    "            #print(\"state:\", curr_state)\n",
    "        else:\n",
    "            districts = pq(tr)('td')\n",
    "            if districts != \"\":\n",
    "                for x in districts:\n",
    "                    dist_name = pq(x)('a').text()\n",
    "                    if dist_name != \"\":\n",
    "                        district_dict = {'year':year, 'state':curr_state}\n",
    "                        district_dict['district'] = dist_name\n",
    "                        district_dict['thelink'] = pq(x)('a').attr.href\n",
    "                        datalist.append(district_dict)\n",
    "                        \n",
    "    print(\"PROCESS COMPLETED FOR YEAR:\", year)\n",
    "    print(\"TOTAL CONSTITUENCIES\", len(datalist))\n",
    "\n",
    "\n",
    "    return pd.DataFrame(datalist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following functions returns a dataframe of candidates from a constituency####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(constituency, state, thelink, year):\n",
    "\n",
    "    masterlink = thelink\n",
    "    thepage = requests.get(masterlink)\n",
    "    doc = pq(thepage.content)\n",
    "\n",
    "    trs = doc('table').eq(2).children('tr')\n",
    "\n",
    "    #print pq(trs)\n",
    "    datalist = []\n",
    "\n",
    "    for tr in trs[1:]:\n",
    "        candidate_dict = {'Year':year, 'State':state, 'Constituency':constituency, 'Winner': 0}\n",
    "        for i,td in enumerate(pq(tr)('td')):\n",
    "            if i == 0:\n",
    "                candidate_dict['Name'] = pq(td)('a').text()\n",
    "                candidate_dict['Link'] = pq(td)('a').attr.href\n",
    "                if pq(td)('font').text() == \"Winner\":\n",
    "                    candidate_dict['Winner'] = 1\n",
    "            if i == 1:\n",
    "                candidate_dict['Party'] = pq(td).text()\n",
    "            if i == 2:\n",
    "                candidate_dict['Criminal_Cases'] = pq(td).text()\n",
    "            if i == 3:\n",
    "                candidate_dict['Education'] = pq(td).text()                \n",
    "            if i == 4:\n",
    "                candidate_dict['Age'] = pq(td).text() \n",
    "            if i == 5:\n",
    "                candidate_dict['Assets_Rs'] = td.text.replace(\"Rs\",'').replace(',','').lstrip()\n",
    "            if i == 6:\n",
    "                candidate_dict['Liabilities_Rs'] = td.text.replace(\"Rs\",'').replace(',','').lstrip()\n",
    "        datalist.append(candidate_dict)\n",
    "    return pd.DataFrame(datalist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting all the constituencies####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching constituencies!\n",
      "PROCESS COMPLETED FOR YEAR: 2004\n",
      "TOTAL CONSTITUENCIES 543\n",
      "Fetching constituencies!\n",
      "PROCESS COMPLETED FOR YEAR: 2009\n",
      "TOTAL CONSTITUENCIES 543\n",
      "Fetching constituencies!\n",
      "PROCESS COMPLETED FOR YEAR: 2014\n",
      "TOTAL CONSTITUENCIES 543\n",
      "CPU times: user 406 ms, sys: 19.7 ms, total: 425 ms\n",
      "Wall time: 7.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "constituency_list = []\n",
    "\n",
    "for year, url in base_urls.items():\n",
    "    constituency_list.append(get_constituents(year, url))\n",
    "\n",
    "constituency_df = pd.concat(constituency_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting candidates for each constituency\n",
    "(Time consuming, can skip and read \"candidates.csv\" from the data folder directly) <br>\n",
    "(Approx Wait Time: 5 min, 53s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FETCHING CANDIDATES!\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"FETCHING CANDIDATES!\")\n",
    "candidates_list = []\n",
    "\n",
    "for index, row in constituency_df.iterrows():\n",
    "    temp_df = get_candidates(row['district'], row['state'], base_urls[row['year']]+row['thelink'], row['year'])\n",
    "    candidates_list.append(temp_df)\n",
    "    \n",
    "candidates_df = pd.concat(candidates_list)\n",
    "print(\"PROCESS COMPLETED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapping Up and writing to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(candidates_df.count())\n",
    "candidates_df[len(candidates_df)-100:len(candidates_df)].head(3)\n",
    "candidates_df.to_csv(\"data/candidates1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above results how the number of values in each column. As the data count is uniform across each column, we can concude the the data scraping has been sucessfully done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 DATA DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comprising of the data of candidiates who contested the Indian General Elections in 2004, 2009 and 2014.<br>\n",
    "We have a dataset of total 19520 candidates across 15 years. (19520 rows)\n",
    "The dataset consists of 13 columns. The columns (features) have been described below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " 1. <b>Unnamed: 0 : </b> Row Number\n",
    " 2. <b>Age : </b> The name of the candidate (String)\n",
    " 3. <b> Assets_Rs : </b> Total decalared assets owned by the candidates in Rupees (Rs.) (Continuous)\n",
    " 4. <b>Constituency : </b> The name of the constituency the candidate is contesting from (String)\n",
    " 5. <b> Criminal_Cases : </b> The number of registered criminal cases against the candidate in the Indian Court (Continuous)\n",
    " 6. <b>Education : </b> Education Level of the Candidate. 7 Different Values: <br>\n",
    "     1. Doctorate : Has a PhD\n",
    "     2. Post Graduate : Has a Master's degree \n",
    "     3. Graduate : Has a Bachelor's degree \n",
    "     4. 12th Pass : Completed School Education, No college education\n",
    "     5. 10th Pass : School Education until 10th Grade\n",
    "     6. 8th Pass : School Education until 8th Grade\n",
    "     7. 5th Pass : School Education until 5th Grade\n",
    "     8. Literate : Can read and write, no formal education\n",
    "     9. Illiterate : Cannot read or write\n",
    "     10. Others : Other Educational Qualifications\n",
    "     11. Not Given : No mention of Educational Qualifications\n",
    " 7. <b>Liabilities_Rs : </b> The amount of Liabilities owed by the candidate in Rupees (Rs.)\n",
    " 9. <b>Name : </b> The Name of the Candidate\n",
    " 10. <b>Party : </b> The political party it represents (Most of the names are abbrevated)\n",
    " 11. <b>State : </b> The state from which the candidate is contestiting from\n",
    " 12. <b>Year : </b> The year in which the data was collected\n",
    " 13. <b>Winner : </b> Whether the candidate won or lost (0 - Lost, 1 - Won) (Identifier) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected from the website is highly disorganized. To make sure the project and the machine leanring model results are correct, certain data cleaning procedures were undertaken. They have been explained below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3.3.1 Checking for Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"candidates.csv\") #Read \"candidates.csv for already stored dataset\"\n",
    "df[df.isnull().any(axis=1)]  #checking and removing null values="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Uniform Typecase:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at our given dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b>For uniformity, converting the values in 'Party' and 'Name' to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Name\"] = df[\"Name\"].apply(lambda x: x.lower())\n",
    "df[\"Party\"] = df[\"Party\"].apply(lambda x: x.lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Removing NULL and values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b>The constituency name can be same for two different constituencies in two different state. This would lead to ambiguity in our calculation. Making a new column 'state_constituency' and combining the state and constituency for the candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"state_constituency\"] = df[\"Constituency\"].apply(lambda x: x.lower()) + df[\"State\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><br> Some candidates failed to decalre their Asset worth. The value for such cases have been listed as 'Nil'. Others have mentioned their worth as '0'.  <br> Removing 'Nil' and '0' rows from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Assets_Rs\"] != \"Nil\"] #Remove 'Nil' asset values\n",
    "df = df[df[\"Assets_Rs\"] != 0] # Remove '0' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"New length of dataset: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Type Conversion and Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><br> Converting all Assets_Rs and Liabilities_Rs values to int. <br>\n",
    "    Taking log of Assets_Rs. and Liabilities_Rs column for reducing computation time and simpler calculation </b> <br>\n",
    "  \n",
    "(Average wait time: 38 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"STARTING PROCESS\")\n",
    "for i,r in df.iterrows():\n",
    "    try:\n",
    "        df.loc[i, 'Assets_Rs'] = int(r.Assets_Rs)\n",
    "        df.loc[i, 'Liabilities_Rs'] = int(r.Liabilities_Rs)\n",
    "    except:\n",
    "        df.loc[i, 'Assets_Rs'] = int(0)\n",
    "        \n",
    "df[\"assets_\"] = np.log(df[\"Assets_Rs\"])\n",
    "df[\"liabilities_\"] = np.log(df[df[\"Liabilities_Rs\"]!=0][\"Liabilities_Rs\"]) #only take log of non zero values\n",
    "df.loc[df[\"liabilities_\"].isnull(), \"liabilities_\"] = 0\n",
    "print(\"PROCESS COMPLETED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5 Feature Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding 'state_constituency', 'Party' and 'Education'  features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(df.state_constituency)\n",
    "df['constituency_']=le.transform(df.state_constituency)\n",
    "\n",
    "le.fit(df.Party)\n",
    "df['party_']=le.transform(df.Party)\n",
    "\n",
    "le.fit(df.Education)\n",
    "df['education_']=le.transform(df.Education)\n",
    "\n",
    "print(\"Final look at cleaned data:\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 FEATURE CALCULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calulating three features from  existing data:\n",
    "1. Incumbency of candidate\n",
    "2. Party Type : Whether the candidate belongs to a national party, state recognized party, unrecognized party or is an independent candidate (No affliation to any political party)\n",
    "3. Inclination: Whether the candidate is inclined to a left wing or right wing politicaL; ideology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Calulating Incumbency Values <br>\n",
    "\n",
    "Due to huge number of discrepencies in the names of candidates, the incumbency value will be calculated based on whether the political party won or lost previously in the same constituency instead of the candidate himself\n",
    "\n",
    "    -1 = Incumbent Candidate \n",
    "     1 = Non-Incumbent/New Candidate\n",
    "\n",
    "(Average Wait Time: 12 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "yrs = [2014, 2009, 2004]\n",
    "df[\"Incumbency\"] = 1\n",
    "print(\"STARTING PROCESS:\")\n",
    "for y in range(len(yrs)-1):   # looping over only the last N-1 years\n",
    "    for c in df[\"state_constituency\"].unique():\n",
    "        win_prty = list(df[(df[\"Year\"]==yrs[y+1]) & (df[\"Winner\"]==1) & (df[\"state_constituency\"]==c)][\"Party\"].unique())\n",
    "        df.loc[(df[\"Year\"]==yrs[y]) & (df[\"state_constituency\"]==c) & (df[\"Party\"].isin(win_prty)), \"Incumbency\"] = -1\n",
    "    print(\"Calculated for year :\", y)\n",
    "print(\"PROCESS COMPLETED!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Calculating Political Party Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Political Parties in India can be classified as:\n",
    "#### 1. National Party:\n",
    "\n",
    "A registered party is recognised as a national party only if it fulfils any one of the following three conditions:\n",
    "\n",
    "A. A party wins 2% of seats in the Lok sabha from at least three different states. <br>\n",
    "B. At a general election to Lok Sabha or Legislative Assembly, the party polls 6% of votes in any four or more states and in addition it wins four Lok Sabha seats. <br>\n",
    "C. A party gets recognition as a state party in four states. [1] <br>\n",
    "\n",
    "#### 2. State Party:\n",
    "A party has to fulfill any of the following conditions for recognition as a state party:\n",
    "\n",
    "A. A party should win minimum three percent of the total number of seats or a minimum of three seats in the Legislative Assembly. <br>\n",
    "B. A party should win at least one seat in the Lok Sabha for every 25 seats or any fraction thereof allotted to that State. <br>\n",
    "C. A party should secure at least six percent of the total valid votes polled during general election to a Lok Sabha or State Legislative Assembly and should, in addition, win at least one Lok Sabha, and two Legislative Assembly seats in that election <br>\n",
    "D. Under the liberalised criteria, one more clause that it will be eligible for recognition as state party if it secures 8% or more of the total valid votes polled in the state, addition to one seat in any state. [2] <br>\n",
    "\n",
    "#### 3. Unrecognized Party:\n",
    "Neither of the above\n",
    "\n",
    "#### 4. Further a candidate can Indpendent (No affiliation to any political party <br> <br>\n",
    "\n",
    "<b> As of 2019, only 8 political parties have been granted the 'national' status.  <br>\n",
    "For the names of state parties, using 'state_parties_performance.csv' which shows the performance of state parties in the recent elections. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_parties_file = pd.read_csv(\"data/state_parties_performance.csv\")\n",
    "state_parties = np.asarray(state_parties_file[\"Party Abbre\"], dtype=str)\n",
    "state_parties = np.char.lower(state_parties)\n",
    "national_parties = np.asarray([\"BSP\",\"BJP\",\"CPI\",\"CPI(M)\",\"INC\",\"NCP\",\"NPP\"], dtype=str)\n",
    "national_parties = np.char.lower(national_parties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a new column 'party_type': <br>\n",
    "    0 = Unrecognized Party\n",
    "    1 = National party\n",
    "    2 = State Party\n",
    "    3 = Independent Candidate (No party affilication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party = df[\"Party\"]\n",
    "all_parties = party.unique()\n",
    "df[\"party_type\"]= 0\n",
    "for i in national_parties:\n",
    "    df.loc[(party == i) &  (party.isin(national_parties)), \"party_type\"] = 1\n",
    "\n",
    "for i in state_parties:\n",
    "    df.loc[(party== i) &  (party.isin(state_parties)), \"party_type\"] = 2\n",
    "\n",
    "#independent candidates (no affiliation to any party)\n",
    "df.loc[(party== \"ind\"), \"party_type\"] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Determining candidate's political inclination:\n",
    "\n",
    "Political parties in India can be left leaning, center leaning, or right leaning. Futher their can be several subcategories in political ideologies like left-to-center or far-right or far-left. Determining these subcategories is difficult due to lack of data online. Further many political parties in India do not follow a strict ideology when it comes to politics as it is evident in the past. Many political parties also tend to join alliances with opposing views for other gains. <br>\n",
    "For the sake of this project, dividing the political parties in 4 categories <br>\n",
    "    1. Left Leaning  = 1\n",
    "    2. Right Leaning = 2\n",
    "    3. Center = 3\n",
    "    4. Independent Candidate(No affilaiton to any political party/inclination Unknown) = 0X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_wing = [\"inc\",\"rjd\", \"ncp\", \"rld\", \"jmm\", \"jknc\", \"mahan dal\", \"iuml\" \"socialist janata (democratic)\", \"kc(m)\", \"rsp\", \"bpf\",\"cpi\", \"jd(s)\", \"inld\", \"bsp\", \"sjp(r)\"]\n",
    "right_wing = [\"bjp\",\"shs\", \"aiadmk\", \"jd(u)\", \"sad\", \"pmk\", \"ljp\", \"dmdk\", \"agp\", \"ajsu party\", \"puthiya tamilagam\", \"all india n.r. congress\", \"pt\", \"pnk\", \"bpf\", \"kec(m)\", \"National Loktantrik Party\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"inclination_\"]= 3\n",
    "for i in left_wing:\n",
    "    df.loc[(party == i) &  (party.isin(left_wing)), \"inclination_\"] = 1\n",
    "\n",
    "for i in right_wing:\n",
    "    df.loc[(party== i) &  (party.isin(right_wing)), \"inclination_\"] = 2\n",
    "\n",
    "#independent candidates (no affiliation to any party)\n",
    "df.loc[(party== \"ind\"), \"inclination_\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final look at the new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. DATA ANALYSIS FOR FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True,\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "\n",
    "plt.gcf().set_size_inches(10, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based upon the above heatmap, The best features to include in the training set will be:\n",
    "\n",
    "\n",
    "1. assets_\n",
    "2. Liabilities_Rs\n",
    "3. education_\n",
    "4. party_\n",
    "5. Criminal_Cases\n",
    "6. Incumbency\n",
    "7. constituency_\n",
    "8. Year\n",
    "9. party_type\n",
    "10. inclination_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. EXPERIMENTS AND CALCULATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 The Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we are creating a regression function $f(c)$ $-> y $ where $c$ denotes candidates $c_1$, $c_2$ , $c_3$ $...$ $c_n$ for all candidates $n$ and y is the 'score' each candidate gets based on the features we train the model on. <br>\n",
    "We can now further compare the candidates such that $f(c_1)$ > $f(c_2)$ > $f(c_3)$ etc. for $y_1$>$y_2$>$y_3$ and tell how good a candidate is and what are his chances of winning. <br> <br>\n",
    "\n",
    "For any candidate, $y$ (score) can be calculated by: <br>\n",
    "$$y = \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3 ... \\theta_n x_n $$\n",
    "\n",
    "for n features, where $x_i$ is the feature and $\\theta_i$ the corresponding coefficient/weight\n",
    "\n",
    "Further as we use the 2014 elections data as the test data, we can determine how unexpectedly skewed the election was towards people who had a lower chance of winning <br>\n",
    "\n",
    "We are also determing the feature importance of each feature using random forest regressor to determine which factors influence the chances of winning from most to least"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 10 features we are basing our calculations on are:\n",
    "\n",
    "1. assets_\n",
    "2. Liabilities_Rs\n",
    "3. education_\n",
    "4. party_\n",
    "5. Criminal_Cases\n",
    "6. Incumbency\n",
    "7. constituency_\n",
    "8. Year\n",
    "9. party_type\n",
    "10. inclination_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gathering required data and spliting the data into train and test data\n",
    "#### For the project, taking 2004 and 2009 data as the train data and 2014 data as the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['assets_','liabilities_','education_','party_','Criminal_Cases','Incumbency','constituency_','Year','party_type', \"inclination_\"]\n",
    "target=['Winner']\n",
    "\n",
    "X_train, X_test = df[df[\"Year\"]!=2014][cols+target],df[df[\"Year\"]==2014][cols+target]\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Calculating Feature Importance using Random Forest Regressor\n",
    "\n",
    "(Approx. Wait Time : 15 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Starting Random Forest!\")\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(X_train[cols], np.ravel(X_train[target]));\n",
    "pred_rf = rf.predict(X_test[cols])\n",
    "print(\"Process Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_score = sorted(map(lambda x: round(x, 4), rf.feature_importances_),reverse=True)\n",
    "print(\"Features sorted by their score:\")\n",
    "sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), cols), \n",
    "             reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Feature Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_score_dict={}\n",
    "for i,j in zip(cols,rf.feature_importances_):\n",
    "    feature_score_dict[i]=j\n",
    "df_fi=pd.DataFrame(feature_score_dict.items(), columns=['name', 'value'])\n",
    "\n",
    "df_fi=df_fi.sort_values('value', axis=0,ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "\n",
    "ax=sns.barplot(x=\"name\", y=\"value\",data=df_fi, palette=sns.light_palette(\"red\", reverse=True,n_colors=10))\n",
    "for item in ax.get_xticklabels():\n",
    "    item.set_rotation(20)\n",
    "ax.set(xlabel='Decision feature', ylabel='Importance ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Defining the Regression Function and Calulating the Candidate Score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Initializing the trainer and fitting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg = Ridge(alpha=1).fit(X_train[cols], X_train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Prediciting test values values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Classifying Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_pred = y_pred\n",
    "b_pred[b_pred < 0.5] = 0\n",
    "b_pred[b_pred >= 0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Calculating Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of calculating accuracy score, a balanced accurqacy score would be a better fir for our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "print(\"Balanced Accuracy Score = \",balanced_accuracy_score(b_pred, X_test[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Calculating Coefficients/Weights of our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = sorted((reg.coef_[0]), reverse = True)\n",
    "print(\"Weights for features (in decreasing order) are:\")\n",
    "print()\n",
    "for i,j in zip(cols,coef):\n",
    "    print(i,(j))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef[3] = 0\n",
    "coef[1] = coef[1] * -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.4 Calculating Score for each candidate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any candidate, $y$ (score) can be calculated by: <br>\n",
    "$$y = \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3 ... \\theta_n x_n $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_dict = {}\n",
    "for i,j in zip(cols,rf.feature_importances_):\n",
    "    y_score_dict[i]=j\n",
    "df_score=pd.DataFrame(y_score_dict.items(), columns=['col', 'score'])\n",
    "df_score1 = df_score.transpose()\n",
    "df_score1  = df_score1[1:]\n",
    "df3 = pd.DataFrame(np.array(df2.values * df_score1.values))\n",
    "df[\"score_\"] = 0\n",
    "df[\"score_\"] = df3.sum(axis = 1)\n",
    "new_df = df[~df[\"score_\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scores for each candidate are:\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing Scores\n",
    "For every $x_i$, <br>\n",
    "$$x_i = \\frac{(x_i - mean)} {Standard Deviation}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_df[\"score_\"].values #returns a numpy array\n",
    "x = (x - x.mean())/x.std()\n",
    "new_df[\"score_\"] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calulated score staistics:\")\n",
    "new_df[\"score_\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 5.3.4 Visualizing Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we the scores for each candidate, we can perform various operations on it. <br>\n",
    "One such experiment can be to compute state-wise and party-wise average score and plot them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ####  Visualizing State-wise avergae score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_state_score = {}\n",
    "for i in new_df[\"State\"].unique():\n",
    "       avg_state_score[i] = new_df[new_df[\"State\"] == i][\"score_\"].mean()\n",
    "\n",
    "df_state_score = pd.DataFrame(avg_state_score.items(), columns= ['state','score_avg'])\n",
    "df_state_score = df_state_score.sort_values(by = \"score_avg\")\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax=sns.barplot(x=\"state\", y=\"score_avg\",data=df_state_score, palette=sns.dark_palette(\"red\", reverse=False,n_colors=38))\n",
    "for item in ax.get_xticklabels():\n",
    "    item.set_rotation(75)\n",
    "ax.set(xlabel='State', ylabel='Average Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can infer from tha above graph that candidates contesting in the states of 'Puducherry' and 'Nagaland' have the worst average scores.<br>\n",
    "While candidates in the states of 'Sikkim' and 'Uttarakhand' have the best scores of all States and Union territories in India for three consecutive elections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ####  Visualizing Party-wise avergae score:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 30 Political Parties in India with candidates having the worst chance of winning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_party_score = {}\n",
    "for i in new_df[\"Party\"].unique():\n",
    "       avg_party_score[i] = new_df[new_df[\"Party\"] == i][\"score_\"].mean()\n",
    "\n",
    "df_party_score = pd.DataFrame(avg_party_score.items(), columns= ['party','score_avg'])\n",
    "df_party_score = df_party_score.sort_values(by = \"score_avg\")\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax=sns.barplot(x=\"party\", y=\"score_avg\",data=df_party_score[:30], palette=sns.dark_palette(\"red\", reverse=False,n_colors=38))\n",
    "for item in ax.get_xticklabels():\n",
    "    item.set_rotation(75)\n",
    "ax.set(xlabel='State', ylabel='Average Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 30 Political Parties in India with candidates having the best chance of winning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax=sns.barplot(x=\"party\", y=\"score_avg\",data=df_party_score[-30:], palette=sns.dark_palette(\"red\", reverse=False,n_colors=38))\n",
    "for item in ax.get_xticklabels():\n",
    "    item.set_rotation(75)\n",
    "ax.set(xlabel='State', ylabel='Average Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further compare the avergae scores of left wing political parties with the right wing and center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ideology_score = {}\n",
    "for i in new_df[\"inclination_\"].unique():\n",
    "       avg_ideology_score[i] = new_df[new_df[\"inclination_\"] == i][\"score_\"].mean()\n",
    "\n",
    "df_ideology_score = pd.DataFrame(avg_ideology_score.items(), columns= ['ideology','score_avg'])\n",
    "df_ideology_score['ideology'] = df_ideology_score['ideology'].replace({0:'Center', 1:'Left-Wing', 2: 'Right Wing', 3:'Independent'})\n",
    "df_ideology_score = df_ideology_score.sort_values(by = \"score_avg\")\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax=sns.barplot(x=\"ideology\", y=\"score_avg\",data=df_ideology_score, palette=sns.dark_palette(\"red\", reverse=False,n_colors=5))\n",
    "for item in ax.get_xticklabels():\n",
    "    item.set_rotation(75)\n",
    "ax.set(xlabel='ideology', ylabel='Average Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the average scores of all political parties are in the the range -0.3 to 0.3 and they vary by a small margin. So the results are either inconclusive in the case or Indian election ecosystem doesn't depend significantly on a candidate's political ideology. (which has been evident in the past)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the f1 score and precision of our model to see fuerther how accurate the calculations are. <br>\n",
    "Further, whether the feature selection of the current model (based on 2004 and 2009 elections) goes along with the trend of 2014 elections can be determined by these metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(f1_score(X_test[target].values, y_pred))\n",
    "print(precision_score(X_test[target].values, y_pred))\n",
    "print(recall_score(X_test[target].values, y_pred))\n",
    "print(confusion_matrix(X_test[target].values, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the F1 score is low for our calculations (~0.1), I conclude that the algorithm and the dataset are not sufficient to determine the outcome of the 2014 elections. <br> <br>\n",
    "\n",
    "The 2014 general elections in India were the most skewed elections where the outcome was the least expected, catching most of the psephologists by surprised. The sudden emergence of Prime Minister Modi's right-wing BJP and the National Democratic Alliance was unanticipated after a 10-year long administrative rule of the left-wing INC and the United Progressive Alliance. <br> <br>\n",
    "<b>The motivation behind this project has always been the unprecedented outcome of 2014 elections. Even though the algorithm and the dataset lags to determine the outcomes, I do hope it highlights the sudden change in the political environment of India in 2014. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The unavailibility of the 2019 election results significantly impacts the model. I hope to continue this project after the 2019 election results are released in the public doman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data source: www.myneta.info\n",
    "2. https://carnegieendowment.org/publications/interactive/india-elects-2019\n",
    "3. https://www.news18.com/lok-sabha-elections-2019/key-candidate-list/\n",
    "4. https://eci.gov.in/files/category/262-recognized-state-parties/\n",
    "5. https://eci.gov.in/files/category/267-recognized-national-parties/\n",
    "6. https://en.wikipedia.org/wiki/List_of_United_Progressive_Alliance_candidates_in_the_2014_Indian_general_election\n",
    "7. https://en.wikipedia.org/wiki/List_of_National_Democratic_Alliance_candidates_in_the_2014_Indian_general_election\n",
    "8. https://github.com/cben/mathdown/wiki/math-in-markdown\n",
    "9. https://medium.com/@andykashyap/top-5-tricks-to-make-plots-look-better-9f6e687c1e08\n",
    "10. https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9\n",
    "11. https://blog.datadive.net/selecting-good-features-part-iii-random-forests/\n",
    "12. https://en.wikipedia.org/wiki/Psephology"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
